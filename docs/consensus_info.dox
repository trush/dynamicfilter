/*!
\page con_info Details About Aggregating Worker Votes
\tableofcontents
This desc. is old and some of the variable names may no longer match, but the
algorithm described is still the same
     Our consensus metric is Complicated. For each IP pair chosen, we do the following
     We gather (NUM_CERTAIN_VOTES) votes on the chosen IP pair
     To take "consensus" we generate a beta distribution from the number of (y/n) votes
       then intigrate over it from zero to (DECISION_THRESHOLD)
      if the probability area is less than (UNCERTAINTY_THRESHOLD) then we have consensus
       else we gather more votes
     This is repeated until one of several conditions is met
       1 - We reach consensus (naturally(Bayes))
       2 - The total number of gathered votes is equal to (CUT_OFF)
       3 - The number of either (yes)s or (no)s on their own is equal to (SINGLE_VOTE_CUTOFF)
     If either cond. (2|3) we take a simple majority vote

General Consensus

 Maximum number of votes to ask for before using Majority Vote as backup metric
                Only rather ambiguous IP pairs should ever actually reach this limit
                 Recomended value (21 for real data) #TODO test more stuff on synth data

 Number of votes for a single result (Y/N) before calling that the winner #TODO remove this!
 This should be depricated soon
 if you're reading this, Jake forgot to take this variable out or was lazy

Bayes:
     The Bayes portion of the alg is weird and bayesian
     we assume no prior knowledge of the IP pair and thus that there is an
   even likelyhood of it being either true or false.
     In the bayesian world we represent everything as a distribution of probability.
     We use a beta-distribution [https://en.wikipedia.org/wiki/Beta_distribution]
     to represent the distribution of our probability. the beta-distribution has two
     parameters which govern its shape, (a&b). we start with both at 1 which is a
     uniform flat distribution. These a and b represent the number of votes for either
     yes or no on a given IP pair where their values should always be 1 more than the
     number of votes for each catagory. To take consensus, we build our distribution
     and integrate over it from zero to DECISION_THRESHOLD. If the total area in that
     area is less than the UNCERTAINTY_THRESHOLD, we have reached consensus.
     The motivation is this. The integration is asking the question:
     "With the data we have right now, what's the probability that the true [...]
     probability is between 0 and (e.g.) 0.5." (Our IP pair has some true ratio of
     yes votes to no votes.) If the probability of the ratio being within that range
     is small enough, (smaller than UNCERTAINTY_THRESHOLD) we can conclude that the
     true ratio must be larger than that. If the probability is low enough, and the
     DECISION_THRESHOLD chosen correctly, we can say that we have determined the
     ratio, and thus know the "true" answer to our question.

    Adaptive Consensus
       Our algorithm can attempt to "Learn" what a good consensus alg. looks like
         by looking at the IP pairs which reach Completion (Total Number of tasks, "Location", etc.)
         Below are the configurations the adaptability. This section is still very
         much in progress and subject to much change
*/
